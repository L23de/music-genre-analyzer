---
title: "Music Data Processing"
author: "Eric Osterman, Ethan Lavi, Emma Closter, Gabrielle Effendi, Lester Huang"
date: "10/28/2022"
output: html_notebook
---

# Install dependencies
```{r}
install.packages("caret")
install.packages("GGally")
```


# Load libraries

```{r}
library(ggplot2)
library(caret)
library(reshape2)
library(GGally)
```

# Load in CSV

```{r}
music <- read.csv("music_data.csv", header=TRUE)
set.seed(42)
```

# Data Cleaning

## Remove Attributes

Attributes that does not mean too much or is difficult to process

```{r}
music$X <- NULL
music$artist_name <- NULL
music$track_name <- NULL
music$lyrics <- NULL
```

## Normalize using standard scaler

All columns get normalized to its mean and unit variance

```{r}
# scale's every column except release_date, genre & topic
# uses the cleaned data and makes X column NULL
for(i in 1:ncol(music)){
  if(!is.element(colnames(music)[i], c("release_date", "genre", "topic"))){
   m = mean(music[,i])
  standard_dev = sd(music[,i])
  music[,i ] = ((music[,i]-m)/standard_dev)
  }
}
```

# Clean Categorical Variables
```{r}
# Convert Genre to Numerical Values
unique(music$genre)
music$genre <- as.numeric(factor(music$genre))

# Bucket the years
music$release_date <- floor((music$release_date - 1950) / 10)
```

# One-Hot Encode
```{r}
# One Hot Encode Topic
unique(music$topic)
music$topicIsSad <- (music$topic == "sadness") * 1
music$topicIsLife <- (music$topic == "world/life") * 1
music$topicIsMusic <- (music$topic == "music") * 1
music$topicIsRomance <- (music$topic == "romantic") * 1
music$topicIsViolence <- (music$topic == "violence") * 1
music$topicIsObscence <- (music$topic == "obscene") * 1
music$topicIsNight <- (music$topic == "night/time") * 1
music$topicIsFeeling <- (music$topic == "feelings") * 1

music$topic <- NULL
```

# Data Visualizations
```{r}
# Correlation Heatmap
# Source: http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
cormat <- cor(music)
# Reorder cormat by correlation
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
  dd <- as.dist((1-cormat)/2)
  hc <- hclust(dd)
  cormat <-cormat[hc$order, hc$order]
}
cormat <- reorder_cormat(cormat)

# Converts df to two-col table
cormat <- melt(cormat, na.rm=TRUE)

# Plot correlaton matrix
par(mar = c(0.1, 0.1, 0.1, 0.1))
ggplot(cormat, aes(x=Var1, y=Var2, fill=value)) + geom_tile(color="white") + scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") + theme_minimal() + theme(axis.text.y=element_text(size=8), axis.text.x = element_text(angle = 90, 
    size = 8, vjust=1))
```

# Train-test Split

K-Fold Cross Validation will be used later on the train to create a train and validation set

```{r}
# The data comes in sorted so we need to scramble the dataset to make effective and balanced splits
music = music[sample(1:nrow(music)),]

# Calculate how many rows to include in testing
split_prop = round(0.8 * nrow(music))

# Create train and test
train = music[1:(split_prop-1),]
test = music[split_prop:nrow(music),]
```


# Save to file

```{r}
# Write to CSVs
write.csv(train, "./train.csv", row.names = TRUE)
write.csv(test, "./test.csv", row.names = TRUE)
```
