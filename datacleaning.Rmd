---
title: "Music Data Processing"
author: "Eric Osterman, Ethan Lavi, Emma Closter, Gabrielle Effendi, Lester Huang"
date: "10/28/2022"
output: html_notebook
---

# Load in CSV
```{r}
music <- read.csv("music_data.csv", header=TRUE)

# Remove the default 'X' column name for the song "index"
colnames(music)[1] <- ''
```

# Data Cleaning

## Remove Attributes
Attributes that does not mean too much or is difficult to process
```{r}
music$artist_name <- NULL
music$track_name <- NULL
music$lyrics <- NULL
```

## Normalize using standard scaler
All columns get normalized to its mean and unit variance
```{r}
# scale's every column except release_date, genre & topic
# uses the cleaned data and makes X column NULL

music <- read.csv(file = 'downloads/tcc_ceds_music.csv', header = TRUE)
music$X <- NULL
music$artist_name <- NULL
music$track_name <- NULL
music$lyrics <- NULL


for(i in 1:ncol(music)){
  if(!is.element(colnames(music)[i], c("release_date", "genre", "topic"))){
   m = mean(music[,i])
  standard_dev = sd(music[,i])
  music[,i ] = ((music[,i]-m)/standard_dev) 
  }
}
```

# Train-test Split
K-Fold Cross Validation will be used later on the train to create a train and validation set
```{r}
# The data comes in sorted so we need to scramble the dataset to make effective and balanced splits
music = music[sample(1:nrow(music)),]

# Calculate how many rows to include in testing
split_prop = round(0.8 * nrow(music))

# Create train and test
train = music[1:(split_prop-1),]
test = music[split_prop:nrow(music),]
```

Save to file
```{r}
# Write to CSVs
write.csv(train, "./train.csv", row.names = TRUE)
write.csv(test, "./test.csv", row.names = TRUE)
```
